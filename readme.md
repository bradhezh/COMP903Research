# Performance Comparison of JavaScript AI Libraries: TensorFlow.js vs ONNX Runtime Web

This project was developed as part of the COMP903 Research Project at **Auckland Institute of Studies**, completed with an **A grade** in 2025.

## üß† Overview

The goal of this project is to evaluate and compare the performance of two popular JavaScript AI libraries ‚Äî **TensorFlow.js** and **ONNX Runtime Web** ‚Äî for in-browser inference.
It provides an end-to-end workflow from Python-based model training to web-based benchmarking.

## üöÄ Features

- **Python pipeline** for model training (TensorFlow & PyTorch), model conversion, and data analysis.
- **Frontend benchmarking app** built with **React (TypeScript)** to test load and inference performance directly in the browser.
- **Node.js scripts** for dataset formatting.
- **Performance metrics** collected for speed and accuracy.
- **Deployed on Vercel**, enabling real-time browser benchmarking.
- **Continuous Integration** using **GitHub Actions**.

## üõ†Ô∏è Tech Stack

### Frontend
- React
- shadcn/ui
- TypeScript
- TensorFlow.js
- ONNX Runtime Web

### Utilities
- Node.js
- Python (TensorFlow, PyTorch, ONNX, NumPy, Pandas, Matplotlib)

### Deployment & Tools
- Vercel
- GitHub Actions

## üìà Results Summary

- **TensorFlow.js** showed better compatibility and ecosystem integration.
- **ONNX Runtime Web** achieved faster performance in most browser environments.
- The findings suggest that ONNX Runtime Web is preferable for performance-critical web inference tasks.

## üßæ License

This project is for academic and demonstration purposes.

---

Developed by **Jingzhou (Brad) Zhang**,
Master of Information Technology, Auckland Institute of Studies (AIS), 2025.
